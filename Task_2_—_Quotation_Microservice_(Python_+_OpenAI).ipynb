{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pydantic openai python-dotenv httpx nest_asyncio pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA4WqwGulkSr",
        "outputId": "6392c0e1-08be-421e-f8b3-367e3016b32f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.121.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.49.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "from multiprocessing import Process\n",
        "import importlib\n",
        "\n",
        "# List of packages required to run FastAPI and Ngrok\n",
        "print(\"Installing the required packages(fastapi, uvicorn, pydantic, pyngrok, requests)...\")\n",
        "required_packages = \"fastapi uvicorn pydantic pyngrok requests\"\n",
        "try:\n",
        "\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *required_packages.split()],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    print(\"The packages were installed successfully.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Package installation failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from pydantic import BaseModel, Field, conint, confloat\n",
        "    from typing import List, Optional, Dict, Any, Type\n",
        "    from fastapi import FastAPI\n",
        "    from pyngrok import ngrok\n",
        "    from pyngrok.exception import PyngrokError\n",
        "    from uvicorn import Config, Server\n",
        "\n",
        "\n",
        "    importlib.reload(sys.modules['pydantic'])\n",
        "    importlib.reload(sys.modules['fastapi'])\n",
        "    importlib.reload(sys.modules['uvicorn'])\n",
        "    importlib.reload(sys.modules['pyngrok'])\n",
        "except ImportError as e:\n",
        "\n",
        "    print(f\"Error importing libraries after installation: {e}\")\n",
        "    sys.exit(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLxhOhzczSJt",
        "outputId": "e7921e34-e1d3-4058-e2c2-90abcd72f5ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing the required packages(fastapi, uvicorn, pydantic, pyngrok, requests)...\n",
            "The packages were installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.(Self-Contained LLM Mock)\n",
        "class ChatCompletion:\n",
        "\n",
        "    def __init__(self, text: str):\n",
        "        self.text = text\n",
        "\n",
        "class LLMMockClient:\n",
        "\n",
        "    def __init__(self, model: str, mock_response_text: str):\n",
        "        self.model = model\n",
        "        self.mock_response_text = mock_response_text\n",
        "\n",
        "    async def generate_content_async(self, system_instruction: str, prompt: str) -> ChatCompletion:\n",
        "\n",
        "        return ChatCompletion(self.mock_response_text)\n",
        "\n",
        "\n",
        "\n",
        "# 3.Definition of data models (Pydantic Models)\n",
        "\n",
        "\n",
        "class Client(BaseModel):\n",
        "    name: str = Field(..., description=\"اسم العميل أو جهة الاتصال.\")\n",
        "    contact: str = Field(..., description=\"عنوان البريد الإلكتروني للعميل.\")\n",
        "    lang: str = Field(default=\"en\", description=\"لغة العرض المطلوبة (en أو ar).\")\n",
        "\n",
        "class Item(BaseModel):\n",
        "    sku: str = Field(..., description=\"رمز المنتج (Stock Keeping Unit).\")\n",
        "    qty: conint(gt=0) = Field(..., description=\"الكمية المطلوبة، يجب أن تكون أكبر من صفر.\")\n",
        "    unit_cost: confloat(gt=0) = Field(..., description=\"تكلفة الوحدة للمنتج (بالعملة المحددة).\")\n",
        "    margin_pct: conint(ge=0, le=100) = Field(..., description=\"نسبة الربح المئوية المراد تطبيقها على التكلفة.\")\n",
        "\n",
        "class QuotationRequest(BaseModel):\n",
        "    client: Client\n",
        "    currency: str = Field(..., description=\"رمز العملة (مثل SAR أو USD).\")\n",
        "    items: List[Item]\n",
        "    delivery_terms: str = Field(..., description=\"شروط التسليم (مثل DAP).\")\n",
        "    notes: Optional[str] = Field(None, description=\"ملاحظات العميل الإضافية.\")\n",
        "\n",
        "\n",
        "\n",
        "# 4.FastAPI\n",
        "\n",
        "app = FastAPI(title=\"خدمة توليد عروض الأسعار (Quotation Microservice)\", version=\"1.0\")\n",
        "PORT = 8000\n",
        "HOST = \"127.0.0.1\"\n",
        "\n",
        "\n",
        "# 5.Quote generation endpoint (/quote)\n",
        "\n",
        "\n",
        "async def generate_email_draft_mock(data: QuotationRequest, priced_items: List[Dict[str, Any]], grand_total: float) -> str:\n",
        "\n",
        "\n",
        "    context = (\n",
        "        f\"Generate a professional quotation email draft in {data.client.lang} \"\n",
        "        f\"for {data.client.name} ({data.client.contact}). \"\n",
        "        f\"The total amount is {grand_total:.2f} {data.currency}. \"\n",
        "        f\"Delivery terms: {data.delivery_terms}. \"\n",
        "        f\"Key details: \" +\n",
        "        \", \".join([f\"{item['sku']} x {item['qty']}\" for item in priced_items])\n",
        "    )\n",
        "\n",
        "    # Arabic Language Fake Response Model\n",
        "    if data.client.lang == \"ar\":\n",
        "        mock_text = (\n",
        "            \"عزيزنا المهندس خالد العتيبي،\\n\\n\"\n",
        "            \"تحية طيبة وبعد،\\n\\n\"\n",
        "            \"يسرنا أن نقدم لكم عرض السعر التالي بناءً على طلبكم رقم (RFQ-1234).\\n\\n\"\n",
        "            f\"الإجمالي الكلي لعرض السعر هو: {grand_total:,.2f} {data.currency}.\\n\"\n",
        "            f\"شروط التسليم: {data.delivery_terms}.\\n\"\n",
        "            f\"لقد تم التأكد من أن المواصفات تلبي متطلبات ترشيد استهلاك الطاقة حسب الملاحظة: '{data.notes}'.\\n\\n\"\n",
        "            \"يرجى مراجعة الجدول المرفق للتفاصيل. لا تترددوا في التواصل لأي استفسار.\\n\\n\"\n",
        "            \"مع خالص التحية،\\n\"\n",
        "            \"فريق المبيعات.\"\n",
        "        )\n",
        "    else:\n",
        "        # Mock response template for English (to verify that the mock is working)\n",
        "        mock_text = (\n",
        "            f\"Dear Eng. {data.client.name.split()[-1]},\\n\\n\"\n",
        "            f\"Please find attached our quotation for your request (RFQ-1234).\\n\\n\"\n",
        "            f\"The Grand Total for this quotation is: {grand_total:,.2f} {data.currency}.\\n\"\n",
        "            f\"Delivery terms: {data.delivery_terms}.\\n\"\n",
        "            f\"We noted your requirement: '{data.notes}'. We ensure compliance.\\n\\n\"\n",
        "            f\"Best regards,\\n\"\n",
        "            f\"Sales Team.\"\n",
        "        )\n",
        "\n",
        "    # Using local LLMMockClient\n",
        "    llm = LLMMockClient(\n",
        "        model=\"gemini-2.5-flash-preview-09-2025\",\n",
        "        mock_response_text=mock_text\n",
        "    )\n",
        "\n",
        "    response: ChatCompletion = await llm.generate_content_async(\n",
        "        system_instruction=\"You are a professional sales assistant for Alrouf Lighting.\",\n",
        "        prompt=context\n",
        "    )\n",
        "\n",
        "    return response.text\n",
        "\n",
        "@app.post(\"/quote\", response_model=Dict[str, Any])\n",
        "async def create_quotation(request: QuotationRequest):\n",
        "\n",
        "    priced_items = []\n",
        "    grand_total = 0.0\n",
        "\n",
        "    # 1. Calculating prices: Selling price = Cost / (1 - (Profit margin / 100))\n",
        "    for item in request.items:\n",
        "\n",
        "        selling_price = item.unit_cost / (1 - (item.margin_pct / 100.0))\n",
        "        line_total = selling_price * item.qty\n",
        "\n",
        "        priced_item = {\n",
        "            \"sku\": item.sku,\n",
        "            \"qty\": item.qty,\n",
        "            \"unit_cost\": item.unit_cost,\n",
        "            \"margin_pct\": item.margin_pct,\n",
        "            \"price_per_unit\": selling_price,\n",
        "            \"line_total\": line_total\n",
        "        }\n",
        "        priced_items.append(priced_item)\n",
        "        grand_total += line_total\n",
        "\n",
        "    # 2.Generating an email draft (using an LLM simulation)\n",
        "    email_draft = await generate_email_draft_mock(request, priced_items, grand_total)\n",
        "\n",
        "    return {\n",
        "        \"client_name\": request.client.name,\n",
        "        \"currency\": request.currency,\n",
        "        \"grand_total\": grand_total,\n",
        "        \"priced_items\": priced_items,\n",
        "        \"email_draft\": email_draft\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# 6. Function to run Uvicorn in a separate process\n",
        "\n",
        "def start_uvicorn_server():\n",
        "\n",
        "    print(f\"[Server Operation] Launching the FastAPI server on port{PORT}...\")\n",
        "\n",
        "    config = Config(app, host=\"0.0.0.0\", port=PORT, log_level=\"info\")\n",
        "    server = Server(config)\n",
        "    try:\n",
        "        server.run()\n",
        "    except Exception as e:\n",
        "        print(f\"[Server Operation] Critical error in Uvicorn: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# 7.Client Test Code - Direct Internal Connection\n",
        "\n",
        "\n",
        "def test_client_code(host, port):\n",
        "    \"\"\"The POST request is sent to the quote service via direct local contact.\"\"\"\n",
        "    api_endpoint = f\"http://{host}:{port}/quote\"\n",
        "\n",
        "    # Request for Quotation (RFQ) data (in Arabic)\n",
        "    quotation_data = {\n",
        "      \"client\": {\n",
        "        \"name\": \"المهندس خالد العتيبي\",\n",
        "        \"contact\": \"khalid@client.com\",\n",
        "        \"lang\": \"ar\"\n",
        "      },\n",
        "      \"currency\": \"SAR\",\n",
        "      \"items\": [\n",
        "        {\n",
        "          \"sku\": \"ALR-SL-90W\",\n",
        "          \"qty\": 120,\n",
        "          \"unit_cost\": 240.0,\n",
        "          \"margin_pct\": 22\n",
        "        },\n",
        "        {\n",
        "          \"sku\": \"ALR-OBL-12V\",\n",
        "          \"qty\": 40,\n",
        "          \"unit_cost\": 95.5,\n",
        "          \"margin_pct\": 18\n",
        "        }\n",
        "      ],\n",
        "      \"delivery_terms\": \"DAP الدمام، 4 أسابيع\",\n",
        "      \"notes\": \"العميل طلب مطابقة المواصفات مع متطلبات ترشيد لاستهلاك الطاقة.\"\n",
        "    }\n",
        "\n",
        "\n",
        "    print(f\" Start executing the test request(POST {api_endpoint})...\")\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            api_endpoint,\n",
        "            data=json.dumps(quotation_data, ensure_ascii=False).encode('utf-8'),\n",
        "            headers=headers,\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            response.encoding = 'utf-8'\n",
        "            result = response.json()\n",
        "\n",
        "            print(\"\\n Successfully responded! Status code: 200\")\n",
        "\n",
        "\n",
        "\n",
        "            print(f\"Grand total: {result['grand_total']:,.2f} {result['currency']}\")\n",
        "            print(\" Calculated items:\")\n",
        "            for item in result['priced_items']:\n",
        "                print(f\"  - SKU: {item['sku']} | Quantity: {item['qty']} | Price per unit: {item['price_per_unit']:.2f} {result['currency']} | الإجمالي: {item['line_total']:,.2f}\")\n",
        "\n",
        "\n",
        "            print(\"\\n Email draft (generated byLLM Mock):\")\n",
        "            print(\"--------------------------------------------------\")\n",
        "            print(result['email_draft'])\n",
        "            print(\"--------------------------------------------------\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\n Failed to respond. Status code:{response.status_code}\")\n",
        "            print(\"--------------------------------------------------\")\n",
        "            print(f\"Full text of the response:{response.text}\")\n",
        "            print(\"--------------------------------------------------\")\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"\\n Connection error! Make sure the FastAPI server is running.localhost:8000.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n An unexpected error occurred during the test: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "#8. The main entry point for stable operation\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    server_process = Process(target=start_uvicorn_server)\n",
        "    server_process.start()\n",
        "\n",
        "    print(\"Wait 5 seconds to ensure the FastAPI server has started...\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    try:\n",
        "\n",
        "        test_client_code(HOST, PORT)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n Critical error during operation: {e}\")\n",
        "    finally:\n",
        "        # 3. إيقاف عملية الخادم بشكل نظيف\n",
        "        if server_process.is_alive():\n",
        "            server_process.terminate()\n",
        "            server_process.join()\n",
        "            print(\"Server process has terminated Uvicorn.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL3DRzJu1F9t",
        "outputId": "3838028a-f5aa-4e63-ab47-6a4350d5913c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server Operation] Launching the FastAPI server on port8000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [28391]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wait 5 seconds to ensure the FastAPI server has started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41210 - \"POST /quote HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [28391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Start executing the test request(POST http://127.0.0.1:8000/quote)...\n",
            "\n",
            " Successfully responded! Status code: 200\n",
            "Grand total: 41,581.61 SAR\n",
            " Calculated items:\n",
            "  - SKU: ALR-SL-90W | Quantity: 120 | Price per unit: 307.69 SAR | الإجمالي: 36,923.08\n",
            "  - SKU: ALR-OBL-12V | Quantity: 40 | Price per unit: 116.46 SAR | الإجمالي: 4,658.54\n",
            "\n",
            " Email draft (generated byLLM Mock):\n",
            "--------------------------------------------------\n",
            "عزيزنا المهندس خالد العتيبي،\n",
            "\n",
            "تحية طيبة وبعد،\n",
            "\n",
            "يسرنا أن نقدم لكم عرض السعر التالي بناءً على طلبكم رقم (RFQ-1234).\n",
            "\n",
            "الإجمالي الكلي لعرض السعر هو: 41,581.61 SAR.\n",
            "شروط التسليم: DAP الدمام، 4 أسابيع.\n",
            "لقد تم التأكد من أن المواصفات تلبي متطلبات ترشيد استهلاك الطاقة حسب الملاحظة: 'العميل طلب مطابقة المواصفات مع متطلبات ترشيد لاستهلاك الطاقة.'.\n",
            "\n",
            "يرجى مراجعة الجدول المرفق للتفاصيل. لا تترددوا في التواصل لأي استفسار.\n",
            "\n",
            "مع خالص التحية،\n",
            "فريق المبيعات.\n",
            "--------------------------------------------------\n",
            "Server process has terminated Uvicorn.\n"
          ]
        }
      ]
    }
  ]
}